---
title: "Proyecto Reglas Asociación"
author: "Juan Alcaraz Otón, Óscar Camacho Barreda"
subitle: "Máster Oficial Ciencia Datos-UV"
output:
  html_document:
    df_print: paged
---

## Qualitative Bankruptcy Data Set

Utilizaremos UNA VERSIÓN PARECIDA PERO NO IGUAL del conjunto de datos `Qualitative_Bankruptcy Data Set` del repositorio *UCI Machine Learning* para trabajar el estudio de las variables Categóricas/Cualitativas y la bondad de las reglas de Asociación para extraer conocimiento de un conjunto de datos, en este caso, predecir la bancarrota (*Bankruptcy*) en base a parámetros cuantitativos/cualitativos preparados por expertos.

Cargar el fichero `Qualitative_Bankruptcy.num.txt` y crear el `data.frame` `QB`.

```{r Apartado 1}
#solucion

rm(list=ls())

library(arules)
library(readr)

QB <- read_csv("Qualitative_Bankruptcy.num.txt", col_names = FALSE)
```

Asigna nombres válidos a las columnas del `data.frame` (usa `make.names` para asegurarte que no contiene símbolos raros). Más información en el fichero `Qualitative_Bankruptcy.info.txt`

```{r Apartado 2}
colnames(QB) <- make.names(c("Industrial Risk", "Management Risk", 
                               "Financial Flexibility","Credibility",
                               "Competitiveness", "Operating Risk", 
                               "Bankruptcy"))
```

Sabiendo que las variables numéricas representan un valor entre 0 y 10 para indicar la valoración del experto de cada variable, prueba a discretizar las variables numéricas en 3 factores ordenados **QB** de ***manera no supervisada*** para estimar la clase (`Bankruptcy`). La etiqueta asociada a valores bajos será "N" de valoración "negative", la etiqueta de valores altos será "P" de "positive" y el resto corresponderá a etiqueta "A" de "average".

```{r Apartado 3}
#solucion

# Pasamos la columna de Bankruptcy a factor
QB$Bankruptcy <- as.factor(QB$Bankruptcy)

# Obtenemos los índices de columnas numéricas y sus nombres
cols_num <- sapply(QB,is.numeric)
nombres_num <- names(QB)[cols_num]

for(col_name in nombres_num){
  
  # Extraemos el vector numérico original de la columna
  vec_num <- QB[[col_name]]
  
  # Dibujamos el histograma
  hist(vec_num,
       breaks = 10,
       main = paste("Discretización de", col_name),
       xlab = "Valoración", 
       col = "lightblue")
  
  # Calculamos los cortes entre los factores sobre el vector original
  cortes <- discretize(vec_num, method = "interval", breaks = 3, onlycuts = TRUE)
  
  # Dibujamos las líneas
  abline(v = cortes, col = "red")
}

# Aplicamos la discretización a las columnas de una copia del df
QB_disc <- QB

QB_disc[, cols_num] <- lapply(QB[, cols_num], function(x) {
  # Asignamos las etiquetas en los intervalos correspondientes
  val_disc <- discretize(x, method = "interval", breaks = 3, labels = c("N", "A", "P"))
  
  # Garantizamos que son factores ordenados con N < A < P
  ordered(val_disc, levels = c("N", "A", "P"))
})
```

Asegúrate que toda las variables son factores de 3 niveles y ORDENADOS que respetan N\<A\<P. La clase `Bankruptcy` debe tener como primera etiqueta "B".

```{r Apartado 4}
#solucion

# Verificamos que la estructura de "Bankruptcy" tenga "B" como primera etiqueta
QB_disc$Bankruptcy <- as.factor(QB_disc$Bankruptcy)
QB_disc$Bankruptcy <- relevel(QB_disc$Bankruptcy, ref = "B")

# Podemos ver que todas las variables numéricas aparecen como factores de 3 niveles ordenados (Ord.factor w/ 3 levels "N"<"A"<"P")
str(QB_disc) 
```

## Análisis Cualitativo

Realiza un estudio del conjunto discretizado para determinar si es apropiado para resolver el problema (estimar Bankruptcy con el menor número de errores) .

### Análisis univariante de las variables Cualitativas

Obtén la descripción de las variables [incluida la clase]{.underline}. Al menos, se debe obtener la tabla de frecuencias y un gráfico para mostrar la frecuencias.

```{r Apartado 5}
#solucion

# Resumimos las variables rápidamente para ver cómo se distribuyen los datos
summary(QB_disc)

# Tablas de frecuencias relativas y absolutas
for (nombre in names(QB_disc)) {
  cat("\n---", nombre, "---\n")
  frec_abs <- table(QB_disc[[nombre]])
  frec_rel <- prop.table(frec_abs)
  
  # Juntamos ambas en una matriz para que se lea mejor
  print(rbind(Absoluta = frec_abs, Relativa = round(frec_rel, 3)))
}

# Gráficos de barras
for (nombre in names(QB_disc)) {
  barplot(table(QB_disc[[nombre]]),
          main = nombre,
          ylab = "Frecuencia")
}
```

[Describe, al menos, 2 conclusiones.]{.underline}

**\>\>\>\<\<\<Conclusiones del análisis univariante...\>\>\>\<\<\<**
- Analizando la variable Bankruptcy, encontramos una proporción de 107 casos de bancarrota (42.8%) frente a 143 de no bancarrota (57.2%). Aunque el escenario ideal sería un equilibrio perfecto del 50%, esta distribución es lo suficientemente balanceada como para evitar que se produzcan sesgos significativos por la presencia mayoritaria de una clase a la hora de generar las reglas.

- En la gran mayoría de las variables predictoras, la categoría "A" (promedio) es la menos frecuente. Esto indica una tendencia en los expertos a evaluar los perfiles de las empresas de forma claramente negativa o positiva, evitando utilizar valoraciones intermedias.

- Las valoraciones negativas "N" son las más comunes en todas las variables. Esto resulta coherente con el alto número de empresas en bancarrota presentes en los datos (42.8%). Dado que una gran parte de las observaciones presentan factores de riesgo con valoración negativa, es esperable que un porcentaje significativo de estas termine quebrando.

### Análisis bivariante de las variables Cualitativas

Obtén la relación entre las variables [y la clase]{.underline} (ej. matrices de contingencia). Determina el grado de asociación (ej. $\chi^2$, CramerV, ...) entre cada variable y la clase.

*Nota: La función PairApply de la librería DescTools permite calcular estadísticos para todos los pares. La función PlotCorr permite representar los resultados de PairApply.*

```{r Apartado 6}
#solucion
library(DescTools)

# Hacemos una función que nos ayudará con el cálculo del test chi2, los argumentos (x, y) se espera que sean los nombres de las variables que se quiere analizar su relación o en su defecto serán los índices o posiciones que ocupan como columna dentro del dataframe
Test_chi2 <- function(x,y){
  return(chisq.test(table(x,y))$p.value)
}

Pruebas_chi2 <- PairApply(QB_disc, Test_chi2)
PlotCorr(Pruebas_chi2)
V_de_Cramer <- PairApply(QB_disc, CramerV)
PlotCorr(V_de_Cramer)
```

Contrasta los resultados con los gráficos de Mosaico de los casos más relevantes.

```{r Apartado 7}
#solucion
library(vcd) 
tab1 <- mosaic(formula = ~ Industrial.Risk + Credibility, data=QB_disc, shade=T, main="Gráfico de mosaico para \n las únicas variables independientes")

# Ahora los gráficos de mosaico para los pares de variables que tienen una dependencia (V de Cramer) mayor
tab2 <- mosaic(formula = ~ Bankruptcy + Competitiveness, data=QB_disc, shade=T, main="Gráfico de mosaico para \n las variables más dependientes")
tab3 <- mosaic(formula = ~ Bankruptcy + Financial.Flexibility, data=QB_disc, shade=T, main="Gráfico de mosaico para \n las variables más dependientes")
```

[Describe, al menos, 2 conclusiones:]{.underline}

- Según el test $\chi^2$ todas las variables discretizadas son dependientes una de otras (o al menos hay evidencia estadística suficiente para creerlo), con la única excepción de el par `Industrial.Risk` y `Credibility`, que es el único caso para el que el $p$-valor es menor que la significancia $0.05$. Y además se observa en el diagrama de mosaico que aproximadamente todas las clases están igualmente repartidas, lo cual apoya la hipótesis de la independencia.

- En cambio, los pares de variables con mayor grado de asociación son los pares `Bankruptcy + Competitiveness` y `Bankruptcy + Financial.Flexibility`. Cosa que podemos confirmar visualmente en el diagrma de mosaico, donde por ejemplo podemos ver que las empresas menos competitivas acaban en bancarrota, mientras que aquellas que no llegaron a la bancarrota montraron un nivel intermedio o alto de competitividad.

**\>\>\>\<\<\<Conclusiones del análisis bivariante...\>\>\>\<\<\<**

## Reglas de Asociación

Transforma el `data.frame` en *transactions* con el nombre `QBt` y analízalas con `summary`.

```{r Apartado 8}
#solution
library(arules)

QBt <- as(QB_disc, "transactions")
summary(QBt)
```

Obtén las reglas de asociación que tienen, al menos, un `support` del 10% y una `confidence` del 100%. ¿Cuántas reglas se obtienen?

```{r Apartado 9}
#solution
rules <- apriori(QBt, parameter = list(supp=0.1, 
                                    conf=1, 
                                    minlen=1, 
                                    maxlen=10,
                                    target="rules"),
        control = list(verbose=T))
```

Muestra las 3 primeras reglas ordenadas por `lift`.

```{r Apartado 10}
#solution
inspect(head(sort(rules, by = "lift"),n=3))
```

Obtén las reglas de asociación que tengan como **ANTECEDENTE** `Bankruptcy=B` . Reduce el número de reglas con las condiciones `lift>2 & count>50`. ¿Observas algún patrón/curiosidad en estas reglas?

*Nota: Representar las reglas ayuda en la interpretación.*

```{r Apartado 11}
#solucion
inspect(subset(rules, subset = lhs %ain% "Bankruptcy=B" & lift>2 & count>50))
```

Obtén las reglas de asociación en las que **no** aparezca la variable`Bankruptcy` (ni en el antecedente ni en la consecuencia). Representa las reglas. ¿Para qué sirven estas reglas/grafo si no aparece la variable objetivo?

```{r Apartado 12}
#solution
inspect(subset(rules, subset = !(lhs %pin% "Bankruptcy") & !(rhs %pin% "Bankruptcy")))
```

Primeramente nos podrían servir para saber que ciertas variables no son independientes unas de otras, aunque ya lo supiésemos por el análisis exploratorio inicial. Otra utilidad sería que estas relaciones nos ayudan a completar el grafo de reglas e implicaciones, sin estas reglas, aunque no incluyan la variable objetivo, las relaciones podrían estar incompletas y es posible que nos faltase información importante sobre los mecanismos mediante los cuales las diferentes variables afectan a la variable objetivo.

## Predicción con reglas de asociación

Desarrolla un modelo de clasificación basado en reglas de asociación para estimar la Bancarrota. Comprueba la bondad del modelo (sensibilidad y especificidad) dividiendo el conjunto de datos en Entrenamiento 80% y Test 20%. Utiliza la función `createDataPartition` y `confusionMatrix` del paquete `caret`.

```{r Apartado 13: Modelo de una sola regla}
set.seed(666)
#solucion

#solucion
library(caret)
library(OneR)

# Partición de los datos en entrenamiento y test
train_Index <- createDataPartition(QB_disc$Bankruptcy, times=1, p=0.8, list=F)
QB_train <- QB_disc[train_Index,]
QB_test <- QB_disc[-train_Index,]

modelo_Una_Regla <- OneR(Bankruptcy~., data=QB_train, verbose = F)
summary(modelo_Una_Regla)

#prediction_test <- factor(predict(modelo_Una_Regla, newdata=QB_test), levels = c("B", "NB"))
#table(prediction_test, QB_test$Bankruptcy)
```

```{r Apartado 13: Modelo CBA de varias reglas}
library(arulesCBA)
modelo_CBA <- CBA(Bankruptcy~., 
                 data=QB_train, 
                 verbose = F,
                 parameter = list(supp=0.1,
                                  conf = 1,
                                  minlen = 1,
                                  maxlen = 10))

prediction_CBA_test <- factor(predict(modelo_CBA, QB_test), levels = c("B", "NB"))
prediction_CBA_train <- factor(predict(modelo_CBA, QB_train), levels = c("B", "NB"))

table(prediction_CBA_test, QB_test$Bankruptcy)
table(prediction_CBA_train, QB_train$Bankruptcy)
```

[Reflexiones sobre el modelo basado en reglas:]{.underline}

**\>\>\>\<\<\<Conclusiones del modelo basado en reglas...\>\>\>\<\<\<**

¿has utilizado todas las variables en el modelo y por qué?

¿has seleccionado reglas y por qué? ¿en base a qué criterio?
